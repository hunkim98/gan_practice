{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2794659822.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    import ..dezero\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import dezero\n",
    "import dezero.functions as F\n",
    "import dezero.layers as L\n",
    "from dezero import DataLoader\n",
    "from dezero.models import Sequential\n",
    "from dezero.optimizers import Adam\n",
    "\n",
    "\n",
    "use_gpu = dezero.cuda.gpu_enable\n",
    "max_epoch = 5\n",
    "batch_size = 128\n",
    "hidden_size = 62\n",
    "\n",
    "fc_channel, fc_height, fc_width = 128, 7, 7\n",
    "\n",
    "gen = Sequential(\n",
    "    L.Linear(1024),\n",
    "    L.BatchNorm(),\n",
    "    F.relu,\n",
    "    L.Linear(fc_channel * fc_height * fc_width),\n",
    "    L.BatchNorm(),\n",
    "    F.relu,\n",
    "    lambda x: F.reshape(x, (-1, fc_channel, fc_height, fc_width)),\n",
    "    L.Deconv2d(fc_channel // 2, kernel_size=4, stride=2, pad=1),\n",
    "    L.BatchNorm(),\n",
    "    F.relu,\n",
    "    L.Deconv2d(1, kernel_size=4, stride=2, pad=1),\n",
    "    F.sigmoid\n",
    ")\n",
    "\n",
    "dis = Sequential(\n",
    "    L.Conv2d(64, kernel_size=4, stride=2, pad=1),\n",
    "    F.leaky_relu,\n",
    "    L.Conv2d(128, kernel_size=4, stride=2, pad=1),\n",
    "    L.BatchNorm(),\n",
    "    F.leaky_relu,\n",
    "    F.flatten,\n",
    "    L.Linear(1024),\n",
    "    L.BatchNorm(),\n",
    "    F.leaky_relu,\n",
    "    L.Linear(1),\n",
    "    F.sigmoid\n",
    ")\n",
    "\n",
    "\n",
    "def init_weight(dis, gen, hidden_size):\n",
    "    # Input dummy data to initialize weights\n",
    "    batch_size = 1\n",
    "    z = np.random.rand(batch_size, hidden_size)\n",
    "    fake_images = gen(z)\n",
    "    dis(fake_images)\n",
    "\n",
    "    for l in dis.layers + gen.layers:\n",
    "        classname = l.__class__.__name__\n",
    "        if classname.lower() in ('conv2d', 'linear', 'deconv2d'):\n",
    "            l.W.data = 0.02 * np.random.randn(*l.W.data.shape)\n",
    "\n",
    "init_weight(dis, gen, hidden_size)\n",
    "\n",
    "opt_g = Adam(alpha=0.0002, beta1=0.5).setup(gen)\n",
    "opt_d = Adam(alpha=0.0002, beta1=0.5).setup(dis)\n",
    "\n",
    "transform = lambda x: (x / 255.0).astype(np.float32)\n",
    "train_set = dezero.datasets.MNIST(train=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "\n",
    "if use_gpu:\n",
    "    gen.to_gpu()\n",
    "    dis.to_gpu()\n",
    "    train_loader.to_gpu()\n",
    "    xp = dezero.cuda.cupy\n",
    "else:\n",
    "    xp = np\n",
    "\n",
    "label_real = xp.ones(batch_size).astype(np.int)\n",
    "label_fake = xp.zeros(batch_size).astype(np.int)\n",
    "test_z = xp.random.randn(25, hidden_size).astype(np.float32)\n",
    "\n",
    "\n",
    "def generate_image():\n",
    "    with dezero.test_mode():\n",
    "        fake_images = gen(test_z)\n",
    "\n",
    "    img = dezero.cuda.as_numpy(fake_images.data)\n",
    "    plt.figure()\n",
    "    for i in range(0, 25):\n",
    "        ax = plt.subplot(5, 5, i+1)\n",
    "        ax.axis('off')\n",
    "        plt.imshow(img[i][0], 'gray')\n",
    "    plt.show()\n",
    "    #plt.savefig('gan_{}.png'.format(idx))\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    avg_loss_d = 0\n",
    "    avg_loss_g = 0\n",
    "    cnt = 0\n",
    "\n",
    "    for x, t in train_loader:\n",
    "        cnt += 1\n",
    "        if len(t) != batch_size:\n",
    "            continue\n",
    "\n",
    "        # (1) Update discriminator\n",
    "        z = xp.random.randn(batch_size, hidden_size).astype(np.float32)\n",
    "        fake = gen(z)\n",
    "        y_real = dis(x)\n",
    "        y_fake = dis(fake.data)\n",
    "        loss_d = F.binary_cross_entropy(y_real, label_real) + \\\n",
    "                 F.binary_cross_entropy(y_fake, label_fake)\n",
    "        gen.cleargrads()\n",
    "        dis.cleargrads()\n",
    "        loss_d.backward()\n",
    "        opt_d.update()\n",
    "\n",
    "        # (2) Update generator\n",
    "        y_fake = dis(fake)\n",
    "        loss_g = F.binary_cross_entropy(y_fake, label_real)\n",
    "        gen.cleargrads()\n",
    "        dis.cleargrads()\n",
    "        loss_g.backward()\n",
    "        opt_g.update()\n",
    "\n",
    "        # Print loss & visualize generator\n",
    "        avg_loss_g += loss_g.data\n",
    "        avg_loss_d += loss_d.data\n",
    "        interval = 100 if use_gpu else 5\n",
    "        if cnt % interval == 0:\n",
    "            epoch_detail = epoch + cnt / train_loader.max_iter\n",
    "            print('epoch: {:.2f}, loss_g: {:.4f}, loss_d: {:.4f}'.format(\n",
    "                epoch_detail, float(avg_loss_g/cnt), float(avg_loss_d/cnt)))\n",
    "            generate_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
