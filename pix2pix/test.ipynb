{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/laksjdjf/dezero-diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from dezero.models import Model, Sequential\n",
    "import dezero.functions as F\n",
    "import dezero.layers as L\n",
    "from dezero.core import Function\n",
    "\n",
    "# from modules.utils import expand_2d\n",
    "import cupy as xp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def expand_2d(x):\n",
    "    return F.expand_dims(F.expand_dims(x, 3), 4)\n",
    "\n",
    "class Cat(Function):\n",
    "    '''\n",
    "    dezeroにはcatが定義されていないので、chatgptに作ってもらった。\n",
    "    '''\n",
    "    def __init__(self, axis=0):\n",
    "        self.axis = axis\n",
    "\n",
    "    def forward(self, *inputs):\n",
    "        z = xp.concatenate(inputs, axis=self.axis)\n",
    "        return z\n",
    "\n",
    "    def backward(self, gz):\n",
    "        inputs = self.inputs\n",
    "        gradients = []\n",
    "        start_idx = 0\n",
    "\n",
    "        for x in inputs:\n",
    "            end_idx = start_idx + x.shape[self.axis]\n",
    "\n",
    "            indices = [slice(None)] * gz.ndim\n",
    "            indices[self.axis] = slice(start_idx, end_idx)\n",
    "\n",
    "            gradients.append(gz[tuple(indices)])\n",
    "\n",
    "            start_idx = end_idx\n",
    "\n",
    "        return tuple(gradients)\n",
    "\n",
    "\n",
    "def cat(inputs, axis=0):\n",
    "    return Cat(axis=axis)(*inputs)\n",
    "\n",
    "\n",
    "class ConvBlock(Model):\n",
    "    '''\n",
    "    複数の畳み込み層+ばっちのーむ+ReLUによるブロック。\n",
    "    最後にアップサンプリングかダウンサンプリングを行うこともある（lastで指定）。\n",
    "    '''\n",
    "    def __init__(self, channels, num_layers, last=None):\n",
    "        '''\n",
    "        channels: 畳み込み層の出力チャンネル数\n",
    "        num_layers: 畳み込み層の数\n",
    "        last: None or \"up\" or \"down\"\n",
    "        '''\n",
    "        super().__init__()\n",
    "        convs = []\n",
    "        norms = []\n",
    "        for _ in range(num_layers):\n",
    "            convs.append(L.Conv2d(channels, kernel_size=3, pad=1, nobias=True))\n",
    "            norms.append(L.BatchNorm())\n",
    "\n",
    "        self.convs = Sequential(*convs)\n",
    "        self.norms = Sequential(*norms)\n",
    "\n",
    "        if last == \"up\":\n",
    "            self.last = L.Deconv2d(channels, kernel_size=4, stride=2, pad=1)\n",
    "        elif last == \"down\":\n",
    "            self.last = L.Conv2d(channels, kernel_size=3, stride=2, pad=1)\n",
    "        else:\n",
    "            self.last = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv, norm in zip(self.convs.layers, self.norms.layers):\n",
    "            x = F.relu(norm(conv(x)))\n",
    "\n",
    "        if self.last is not None:\n",
    "            x = self.last(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(Model):\n",
    "    def __init__(self, out_channels=1, context_dim=10, hidden_channels=16, num_blocks=2, num_layers=3):\n",
    "        '''\n",
    "        out_channels: 出力画像のチャンネル数\n",
    "        context_dim: ラベルの数\n",
    "        hidden_channels: 中間のチャンネル数、ダウンサンプルごとに2倍になる。\n",
    "        num_blocks: ブロックの数。\n",
    "        num_layers: ブロックごとの畳み込み層の数。\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.context_dim = 10\n",
    "        self.conv_in = L.Conv2d(hidden_channels, kernel_size=3, pad=1)\n",
    "\n",
    "        # 時刻[0,1000]を全結合層に入力する。本当はsinとか使うやつにしたい。\n",
    "        time_embs = []\n",
    "        for i in range(num_blocks):\n",
    "            if i == 0:\n",
    "                time_embs.append(L.Linear(hidden_channels))\n",
    "            else:\n",
    "                time_embs.append(L.Linear(hidden_channels*(2**(i-1))))\n",
    "        self.time_embs = Sequential(*time_embs)\n",
    "\n",
    "        # one hot vectorのラベルを全結合層に入力する。\n",
    "        context_embs = []\n",
    "        for i in range(num_blocks):\n",
    "            if i == 0:\n",
    "                context_embs.append(L.Linear(hidden_channels))\n",
    "            else:\n",
    "                context_embs.append(L.Linear(hidden_channels*(2**(i-1))))\n",
    "        self.context_embs = Sequential(*context_embs)\n",
    "\n",
    "        self.down_blocks = Sequential(\n",
    "            *[ConvBlock(hidden_channels*(2**i), num_layers, \"down\") for i in range(num_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mid_blocks = ConvBlock(hidden_channels*2**num_blocks, num_layers)\n",
    "\n",
    "        self.up_blocks = Sequential(\n",
    "            *[ConvBlock(hidden_channels*(2**(num_blocks-i)), num_layers, \"up\") for i in range(num_blocks)]\n",
    "        )\n",
    "\n",
    "        self.conv_out = L.Conv2d(out_channels, kernel_size=3, pad=1)\n",
    "\n",
    "    def forward(self, x, t, context):\n",
    "        t = t.astype(xp.float32) / 1000 # [0,1000] -> [0,1]\n",
    "        h = self.conv_in(x)\n",
    "        hs = [h] # skip connection\n",
    "        for down_block, time_emb, context_emb in zip(self.down_blocks.layers, self.time_embs.layers, self.context_embs.layers):\n",
    "            emb = time_emb(t) + context_emb(context) # 時刻埋め込み、ラベル埋め込み\n",
    "            emb = expand_2d(emb)\n",
    "            h = down_block(h + emb)\n",
    "            hs.append(h) # skip connection\n",
    "\n",
    "        h = self.mid_blocks(h)\n",
    "\n",
    "        for up_block in self.up_blocks.layers:\n",
    "            res = hs.pop()\n",
    "            h = up_block(cat((h, res), axis=1)) # skip connectionを結合\n",
    "\n",
    "        h = self.conv_out(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x = xp.random.randn(1, 1, 28, 28).astype(xp.float32)\n",
    "    t = xp.random.randint(0, 1000, size=(1, 1)).astype(xp.int32)\n",
    "    c = xp.array([[1]])\n",
    "    model = UNet(1, 4, 2, 2)\n",
    "    model.to_gpu()\n",
    "    y = model(x, t, c)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as xp\n",
    "\n",
    "\n",
    "class DDPM:\n",
    "    def __init__(self, beta_start=1e-4, beta_end=0.02, T=1000):\n",
    "        '''\n",
    "        Denoise Diffusion Probabilistic Modelの実装\n",
    "        引数のデフォルトは論文通りの値\n",
    "        '''\n",
    "        self.beta_start = beta_start # beta_0\n",
    "        self.beta_end = beta_end # beta_T\n",
    "        self.T = T \n",
    "        self.beta = xp.linspace(beta_start, beta_end, T) # beta_0, ..., beta_T\n",
    "        self.sqrt_beta = xp.sqrt(self.beta) \n",
    "        self.alpha = 1 - self.beta # alpha_0, ..., alpha_T\n",
    "        self.alpha_bar = xp.cumprod(self.alpha) # Π_{i=0}^t alpha_i\n",
    "        self.sqrt_alpha_bar = xp.sqrt(self.alpha_bar) \n",
    "        self.beta_bar = 1 - self.alpha_bar\n",
    "        self.sqrt_beta_bar = xp.sqrt(self.beta_bar)\n",
    "        self.one_over_sqrt_alpha = 1 / xp.sqrt(self.alpha) # ddpm.stepで使う\n",
    "        self.beta_over_sqrt_beta_bar = self.beta / self.sqrt_beta_bar # ddpm.stepで使う\n",
    "\n",
    "    def add_noise(self, x, noise, t):\n",
    "        '''\n",
    "        時刻tに応じたノイズを加える\n",
    "        x_t = sqrt_alpha_bar_t * x_0 + sqrt_beta_bar_t * noise\n",
    "        '''\n",
    "        return expand_2d(self.sqrt_alpha_bar[t]) * x + expand_2d(self.sqrt_beta_bar[t]) * noise\n",
    "\n",
    "    def step(self, x, noise_pred, t):\n",
    "        '''\n",
    "        x_t -> x_{t-1}のサンプリング\n",
    "        x_{t-1} = 1/sqrt_alpha_t * (x_t - beta_t/sqrt_beta_bar_t * noise_pred) + sqrt_beta_t * noise\n",
    "        '''\n",
    "        noise = xp.random.randn(*x.shape)\n",
    "        prev_x = self.one_over_sqrt_alpha[t] * (x - self.beta_over_sqrt_beta_bar[t] * noise_pred) + self.sqrt_beta[t] * noise\n",
    "        return prev_x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ddpm = DDPM()\n",
    "    x = xp.random.randn(2, 3, 28, 28)\n",
    "    noise_pred = xp.random.randn(2, 3, 28, 28)\n",
    "    t = 999\n",
    "    ddpm.step(x, noise_pred, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import dezero\n",
    "import dezero.functions as F\n",
    "from PIL import Image\n",
    "# from modules.unet import UNet\n",
    "import cupy as xp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Diffusion:\n",
    "    '''\n",
    "    ノイズ予測・サンプラーを受け取って画像生成・学習ステップを定義する。\n",
    "    '''\n",
    "\n",
    "    def __init__(self, unet, sampler):\n",
    "        self.unet = unet\n",
    "        self.unet.to_gpu()\n",
    "        self.sampler = sampler\n",
    "\n",
    "    def generate(self, context, channels, height, width, cfg_scale = 1.0):\n",
    "        '''\n",
    "        画像生成を行うメソッド。\n",
    "        \n",
    "        context: ラベルのxp配列\n",
    "        '''\n",
    "        batch_size = context.shape[0]\n",
    "        with dezero.test_mode():\n",
    "            with dezero.no_grad():\n",
    "                x = xp.random.randn(batch_size, channels, height, width) # 初期ノイズ x_0\n",
    "                for t in tqdm(reversed(range(1000)), total=1000): # t = 999, ..., 0\n",
    "                    noise_pred = self.unet(x, xp.array([[t]]*batch_size).astype(xp.int32), context) # ノイズ予測\n",
    "                    if cfg_scale != 1.0:\n",
    "                        noise_pred_uncond = self.unet(x, xp.array([[t]]*batch_size).astype(xp.int32), context * 0) # ノイズ予測\n",
    "                        noise_pred = noise_pred * cfg_scale + noise_pred_uncond * (1 - cfg_scale)\n",
    "                    x = self.sampler.step(x, noise_pred, t) # x_{t+1} -> x_{t}\n",
    "\n",
    "        images = []\n",
    "        for image in x:\n",
    "            image = (xp.clip(image.data*127.5 + 127.5, 0, 255)).astype(xp.uint8) # 0~255に変換\n",
    "            image = xp.asnumpy(image)\n",
    "            image = image.transpose(1, 2, 0).squeeze()\n",
    "            image = Image.fromarray(image)\n",
    "            images.append(image)\n",
    "        return images\n",
    "    \n",
    "\n",
    "    def generate_grid(self, num_images, channels, height, width, image_path, id2label, cfg_scale = 1.0):\n",
    "        '''\n",
    "        生成画像をラベルごとにグリッド状に並べて保存するメソッド。\n",
    "        '''\n",
    "        num_labels = self.unet.context_dim\n",
    "        fig, axes = plt.subplots(num_labels, num_images, figsize=(7, 14))\n",
    "        images = self.generate(xp.eye(num_labels).repeat(num_images, axis=0),channels, height, width, cfg_scale)\n",
    "        for i in range(num_labels):\n",
    "            for j in range(num_images):\n",
    "                axes[i, j].imshow(images[i*num_images+j], cmap='gray')\n",
    "                axes[i, j].axis('off')\n",
    "\n",
    "            axes[i, 0].text(-0.3, 0.5, f'{id2label[i]}', fontsize=12, verticalalignment='center', horizontalalignment='right', transform=axes[i, 0].transAxes)\n",
    "        fig.savefig(image_path)\n",
    "\n",
    "    def train_step(self, image, context):\n",
    "        '''\n",
    "        学習1ステップ分を実装、lossを返す。\n",
    "        '''\n",
    "\n",
    "        #　加えるノイズ\n",
    "        noise = xp.random.randn(*image.shape)\n",
    "        \n",
    "        #　ランダムな時刻を選択\n",
    "        t = xp.random.randint(0, 1000, size=(image.shape[0], 1)).astype(xp.int32)\n",
    "        \n",
    "        # ノイズを加える\n",
    "        noisy_image = self.sampler.add_noise(image, noise, t)\n",
    "        \n",
    "        # ノイズ予測\n",
    "        noise_pred = self.unet(noisy_image, t, context)\n",
    "        \n",
    "        # ノイズ予測と実際のノイズのMSEを計算\n",
    "        loss = F.mean_squared_error(noise, noise_pred) / (image.shape[1]*image.shape[2]*image.shape[3])\n",
    "        return loss\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unet = UNet()\n",
    "    ddpm = DDPM()\n",
    "    diffusion = Diffusion(unet, ddpm)\n",
    "    image = xp.random.randn(3, 1, 28, 28)\n",
    "    loss = diffusion.train_step(image, xp.array([[0, 1, 2]]))\n",
    "    # images = diffusion.generate(xp.array([0,1,2]),1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dezero\n",
    "from dezero import DataLoader\n",
    "from tqdm import tqdm\n",
    "from dezero.transforms import Compose, ToFloat, Normalize\n",
    "import numpy as np\n",
    "import cupy as xp\n",
    "import os\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, diffusion, batch_size, lr, ucg=0.1, output_dir=\"outputs\", dataset=\"mnist\"):\n",
    "        self.batch_size = batch_size\n",
    "        self.diffusion = diffusion\n",
    "        self.ucg = ucg\n",
    "        if dataset == \"mnist\":\n",
    "            self.train_set = dezero.datasets.MNIST(train=True, transform=Compose([ToFloat(), Normalize(127.5, 127.5)]),)\n",
    "        elif dataset == \"cifar10\":\n",
    "            self.train_set = dezero.datasets.CIFAR10(train=True, transform=Compose([ToFloat(), Normalize(127.5, 127.5)]),)\n",
    "        else:\n",
    "            raise ValueError(f\"{dataset} is not supported.\")\n",
    "        \n",
    "        self.train_loader = DataLoader(self.train_set, batch_size)\n",
    "        self.train_loader.to_gpu()\n",
    "        \n",
    "        self.optimizer = dezero.optimizers.Adam().setup(self.diffusion.unet)\n",
    "        self.optimizer.add_hook(dezero.optimizers.WeightDecay(lr))\n",
    "        \n",
    "        self.output_dir = os.path.join(output_dir, \"models\")\n",
    "        self.image_dir = os.path.join(output_dir, \"images\")\n",
    "        self.log_dir = os.path.join(output_dir, \"logs\")\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        os.makedirs(self.image_dir, exist_ok=True)\n",
    "        os.makedirs(self.log_dir, exist_ok=True)\n",
    "\n",
    "    def train(self, epochs, save_n_epochs=5, sample_cfg_scale=3.0, limited_steps=10000000):\n",
    "        progress_bar = tqdm(range(epochs*len(self.train_set)//self.batch_size), desc=\"Total Steps\", leave=False)\n",
    "        loss_ema = None\n",
    "        loss_emas = []\n",
    "        for epoch in range(epochs):\n",
    "            steps = 0\n",
    "            for x, c in self.train_loader:\n",
    "\n",
    "                ucg_random = xp.random.uniform(0, 1, size=(x.shape[0], 1)).astype(xp.float32) > self.ucg\n",
    "                context = xp.eye(self.diffusion.unet.context_dim)[c] # one hot vector化\n",
    "                context *= ucg_random\n",
    "                \n",
    "                loss = self.diffusion.train_step(x, context)\n",
    "                self.diffusion.unet.cleargrads()\n",
    "                loss.backward()\n",
    "                self.optimizer.update()\n",
    "\n",
    "                if loss_ema is not None:\n",
    "                    loss_ema = 0.9 * loss_ema + 0.1 * float(loss.data)\n",
    "                else:\n",
    "                    loss_ema = float(loss.data)\n",
    "                loss_emas.append(loss_ema)\n",
    "                \n",
    "                progress_bar.update(1)\n",
    "                progress_bar.set_postfix({\"loss\": loss_ema})\n",
    "                steps += 1\n",
    "                if steps > limited_steps: # test用\n",
    "                    break\n",
    "\n",
    "            if ((epoch+1) % save_n_epochs) == 0:\n",
    "                self.diffusion.unet.save_weights(os.path.join(self.output_dir, f\"model_{epoch:02}.npz\"))\n",
    "                self.diffusion.unet.to_gpu()  # セーブ時にcpuに移動してしまう仕様\n",
    "                np.save(os.path.join(self.log_dir, f\"log_{epoch:02}.npy\"), np.array(loss_emas))\n",
    "                self.diffusion.generate_grid(4, x.shape[1], x.shape[2], x.shape[3], os.path.join(self.image_dir, f\"image_{epoch:02}.png\"), self.train_set.labels(), cfg_scale=sample_cfg_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    }
   ],
   "source": [
    "dataset = \"mnist\" # \"mnist\" or \"cifar10\"\n",
    "unet = UNet(out_channels=1 if dataset ==\"mnist\" else 3, hidden_channels=64, num_layers=2)\n",
    "ddpm = DDPM()\n",
    "diffusion = Diffusion(unet, ddpm)\n",
    "trainer = Trainer(\n",
    "    diffusion,\n",
    "    batch_size=256,\n",
    "    lr = 1e-5,\n",
    "    output_dir=\"mnist\",\n",
    "    dataset=dataset\n",
    ")\n",
    "\n",
    "trainer.train(1, save_n_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:21<00:00, 45.68it/s]\n"
     ]
    }
   ],
   "source": [
    "gen = trainer.diffusion.generate(xp.eye(10), 1, 28, 28)\n",
    "for i, image in enumerate(gen):\n",
    "    image.save(f\"test_{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "trainer.diffusion.unet.save_weights(\"diffusion.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
